## Course on Generative Deep Learning methods

### Week 1: Style Transfer

[Style Transfer Paper](https://arxiv.org/abs/1508.06576)

[Perceptual Losses](https://cs.stanford.edu/people/jcjohns/eccv16/) Paper with much faster implementation of style transfer in real time

[Paper](https://arxiv.org/pdf/1311.2901.pdf) On Visualising and understanding Convolutional Neural Networks

[Einsum](https://www.youtube.com/watch?v=pkVwUVEHmfI&ab_channel=AladdinPersson) super useful function in python to do matrix operations 


[- Exploring the structure of a real-time, arbitrary neural artistic stylization network (Ghiasi, Lee, Kudlur, Dumoulin & Shlens,
  2017)](https://arxiv.org/pdf/1705.06830.pdf)


- Tensorflow tutorial on Convolutional [VAEs](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/generative/cvae.ipynb)

- [Kullback-Liebler Divergence] (https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence)

- [Paper](https://arxiv.org/abs/2002.07514) on balancing KL loss and reconstruction loss in VAEs

# GANs

- [Coursera GAN specialisation](https://www.deeplearning.ai/generative-adversarial-networks-specialization/)

- [Paper](https://arxiv.org/abs/1706.02515) on self-normalising neural networks. talks about Selu activation function used in
  GANs

- Deep Convolutional GANS [paper](https://arxiv.org/pdf/1511.06434.pdf)

- Leaky Re-LU [activation] (https://www.tensorflow.org/api_docs/python/tf/keras/layers/LeakyReLU)


